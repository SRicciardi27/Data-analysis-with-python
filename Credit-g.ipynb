{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification problem in German credit data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to 'train' using python for machine learning applications. In this notebook we are going to analyze the \n",
    "**Statlog (German Credit Data)** Data Set, avaible thanks to Dua, D. and Graff, C. (2019) at [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science. In this dataset the profiles of the clients of some German banks are stored, in particular they are described as good or bad credit risks. Let's load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      "checking_status           1000 non-null object\n",
      "duration                  1000 non-null int64\n",
      "credit_history            1000 non-null object\n",
      "purpose                   1000 non-null object\n",
      "credit_amount             1000 non-null int64\n",
      "savings_status            1000 non-null object\n",
      "employment                1000 non-null object\n",
      "installment_commitment    1000 non-null int64\n",
      "personal_status           1000 non-null object\n",
      "other_parties             1000 non-null object\n",
      "residence_since           1000 non-null int64\n",
      "property_magnitude        1000 non-null object\n",
      "age                       1000 non-null int64\n",
      "other_payment_plans       1000 non-null object\n",
      "housing                   1000 non-null object\n",
      "existing_credits          1000 non-null int64\n",
      "job                       1000 non-null object\n",
      "num_dependents            1000 non-null int64\n",
      "own_telephone             1000 non-null object\n",
      "foreign_worker            1000 non-null object\n",
      "class                     1000 non-null object\n",
      "dtypes: int64(7), object(14)\n",
      "memory usage: 164.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_status</th>\n",
       "      <th>duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>credit_amount</th>\n",
       "      <th>savings_status</th>\n",
       "      <th>employment</th>\n",
       "      <th>installment_commitment</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_parties</th>\n",
       "      <th>...</th>\n",
       "      <th>property_magnitude</th>\n",
       "      <th>age</th>\n",
       "      <th>other_payment_plans</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>job</th>\n",
       "      <th>num_dependents</th>\n",
       "      <th>own_telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'&lt;0'</td>\n",
       "      <td>6</td>\n",
       "      <td>'critical/other existing credit'</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1169</td>\n",
       "      <td>'no known savings'</td>\n",
       "      <td>'&gt;=7'</td>\n",
       "      <td>4</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>67</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'0&lt;=X&lt;200'</td>\n",
       "      <td>48</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>5951</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>2</td>\n",
       "      <td>'female div/dep/mar'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>22</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'no checking'</td>\n",
       "      <td>12</td>\n",
       "      <td>'critical/other existing credit'</td>\n",
       "      <td>education</td>\n",
       "      <td>2096</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'4&lt;=X&lt;7'</td>\n",
       "      <td>2</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>49</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>'unskilled resident'</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'&lt;0'</td>\n",
       "      <td>42</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>7882</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'4&lt;=X&lt;7'</td>\n",
       "      <td>2</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>'life insurance'</td>\n",
       "      <td>45</td>\n",
       "      <td>none</td>\n",
       "      <td>'for free'</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>'&lt;0'</td>\n",
       "      <td>24</td>\n",
       "      <td>'delayed previously'</td>\n",
       "      <td>'new car'</td>\n",
       "      <td>4870</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>3</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'no known property'</td>\n",
       "      <td>53</td>\n",
       "      <td>none</td>\n",
       "      <td>'for free'</td>\n",
       "      <td>2</td>\n",
       "      <td>skilled</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>'no checking'</td>\n",
       "      <td>36</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>education</td>\n",
       "      <td>9055</td>\n",
       "      <td>'no known savings'</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>2</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'no known property'</td>\n",
       "      <td>35</td>\n",
       "      <td>none</td>\n",
       "      <td>'for free'</td>\n",
       "      <td>1</td>\n",
       "      <td>'unskilled resident'</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>'no checking'</td>\n",
       "      <td>24</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>furniture/equipment</td>\n",
       "      <td>2835</td>\n",
       "      <td>'500&lt;=X&lt;1000'</td>\n",
       "      <td>'&gt;=7'</td>\n",
       "      <td>3</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'life insurance'</td>\n",
       "      <td>53</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>skilled</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>'0&lt;=X&lt;200'</td>\n",
       "      <td>36</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>'used car'</td>\n",
       "      <td>6948</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>'1&lt;=X&lt;4'</td>\n",
       "      <td>2</td>\n",
       "      <td>'male single'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>35</td>\n",
       "      <td>none</td>\n",
       "      <td>rent</td>\n",
       "      <td>1</td>\n",
       "      <td>'high qualif/self emp/mgmt'</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>'no checking'</td>\n",
       "      <td>12</td>\n",
       "      <td>'existing paid'</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>3059</td>\n",
       "      <td>'&gt;=1000'</td>\n",
       "      <td>'4&lt;=X&lt;7'</td>\n",
       "      <td>2</td>\n",
       "      <td>'male div/sep'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>'real estate'</td>\n",
       "      <td>61</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>'unskilled resident'</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'0&lt;=X&lt;200'</td>\n",
       "      <td>30</td>\n",
       "      <td>'critical/other existing credit'</td>\n",
       "      <td>'new car'</td>\n",
       "      <td>5234</td>\n",
       "      <td>'&lt;100'</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>4</td>\n",
       "      <td>'male mar/wid'</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>car</td>\n",
       "      <td>28</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>'high qualif/self emp/mgmt'</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_status  duration                    credit_history  \\\n",
       "0            '<0'         6  'critical/other existing credit'   \n",
       "1      '0<=X<200'        48                   'existing paid'   \n",
       "2   'no checking'        12  'critical/other existing credit'   \n",
       "3            '<0'        42                   'existing paid'   \n",
       "4            '<0'        24              'delayed previously'   \n",
       "5   'no checking'        36                   'existing paid'   \n",
       "6   'no checking'        24                   'existing paid'   \n",
       "7      '0<=X<200'        36                   'existing paid'   \n",
       "8   'no checking'        12                   'existing paid'   \n",
       "9      '0<=X<200'        30  'critical/other existing credit'   \n",
       "\n",
       "               purpose  credit_amount      savings_status  employment  \\\n",
       "0             radio/tv           1169  'no known savings'       '>=7'   \n",
       "1             radio/tv           5951              '<100'    '1<=X<4'   \n",
       "2            education           2096              '<100'    '4<=X<7'   \n",
       "3  furniture/equipment           7882              '<100'    '4<=X<7'   \n",
       "4            'new car'           4870              '<100'    '1<=X<4'   \n",
       "5            education           9055  'no known savings'    '1<=X<4'   \n",
       "6  furniture/equipment           2835       '500<=X<1000'       '>=7'   \n",
       "7           'used car'           6948              '<100'    '1<=X<4'   \n",
       "8             radio/tv           3059            '>=1000'    '4<=X<7'   \n",
       "9            'new car'           5234              '<100'  unemployed   \n",
       "\n",
       "   installment_commitment       personal_status other_parties  ...  \\\n",
       "0                       4         'male single'          none  ...   \n",
       "1                       2  'female div/dep/mar'          none  ...   \n",
       "2                       2         'male single'          none  ...   \n",
       "3                       2         'male single'     guarantor  ...   \n",
       "4                       3         'male single'          none  ...   \n",
       "5                       2         'male single'          none  ...   \n",
       "6                       3         'male single'          none  ...   \n",
       "7                       2         'male single'          none  ...   \n",
       "8                       2        'male div/sep'          none  ...   \n",
       "9                       4        'male mar/wid'          none  ...   \n",
       "\n",
       "    property_magnitude age  other_payment_plans     housing existing_credits  \\\n",
       "0        'real estate'  67                 none         own                2   \n",
       "1        'real estate'  22                 none         own                1   \n",
       "2        'real estate'  49                 none         own                1   \n",
       "3     'life insurance'  45                 none  'for free'                1   \n",
       "4  'no known property'  53                 none  'for free'                2   \n",
       "5  'no known property'  35                 none  'for free'                1   \n",
       "6     'life insurance'  53                 none         own                1   \n",
       "7                  car  35                 none        rent                1   \n",
       "8        'real estate'  61                 none         own                1   \n",
       "9                  car  28                 none         own                2   \n",
       "\n",
       "                           job num_dependents  own_telephone foreign_worker  \\\n",
       "0                      skilled              1            yes            yes   \n",
       "1                      skilled              1           none            yes   \n",
       "2         'unskilled resident'              2           none            yes   \n",
       "3                      skilled              2           none            yes   \n",
       "4                      skilled              2           none            yes   \n",
       "5         'unskilled resident'              2            yes            yes   \n",
       "6                      skilled              1           none            yes   \n",
       "7  'high qualif/self emp/mgmt'              1            yes            yes   \n",
       "8         'unskilled resident'              1           none            yes   \n",
       "9  'high qualif/self emp/mgmt'              1           none            yes   \n",
       "\n",
       "  class  \n",
       "0  good  \n",
       "1   bad  \n",
       "2  good  \n",
       "3  good  \n",
       "4   bad  \n",
       "5  good  \n",
       "6  good  \n",
       "7  good  \n",
       "8  good  \n",
       "9   bad  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "credit = pd.read_csv('data\\credit-g.csv')\n",
    "credit.info()\n",
    "credit.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have : \n",
    "- checking_status : status of existing checking account, in Deutsche Mark.\n",
    "- duration\t: duration in month.\n",
    "- credit_history : History of the credits given to the client.\n",
    "- purpose :\tpurpose of the credit \n",
    "- credit_amount : amount of the credit\n",
    "- savings_status : status of savings account/bonds, in Deutsche Mark.\n",
    "- employment : number of years of the present employment.\n",
    "- installment_commitment : \t\n",
    "- personal_status :marital status and sex\n",
    "- other_parties\t: other debtors / guarantors\n",
    "- residence_since : \n",
    "- property_magnitude : properties of the client\t\n",
    "- age :\tage of the client\n",
    "- other_payment_plans : other installment plans\n",
    "- housing : the state of client's house\n",
    "- existing_credits : number of existing credits at this bank\n",
    "- job :\texpertise of the client\n",
    "- num_dependents : number of people being liable to provide maintenance for\n",
    "- own_telephone\t: If the client has a telephone or not\n",
    "- foreign_worker : If the client is a foreigner\n",
    "- class : If the client is good or bad credit risks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to predict if client's profile is good or bad. To achieve this purpose we need a classification algorithm. We could use a simple **Decision tree** or a more sophisticated **Random Forest** or,why not a **Logistic Regression**,using scikit-learn libraries : [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html), [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) and [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Let's work on the textual fields in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a **one hot encoding** transformation on the string fields in the dataset because scikit-learn libray for classification use only numerical fields. In pandas there is [get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) function for this kind of problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['checking_status','credit_history','purpose','savings_status','employment','personal_status','other_parties','property_magnitude','other_payment_plans','housing','job','own_telephone','foreign_worker']\n",
    "\n",
    "credit= pd.get_dummies(credit,columns = features)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 62 columns):\n",
      "duration                                           1000 non-null int64\n",
      "credit_amount                                      1000 non-null int64\n",
      "installment_commitment                             1000 non-null int64\n",
      "residence_since                                    1000 non-null int64\n",
      "age                                                1000 non-null int64\n",
      "existing_credits                                   1000 non-null int64\n",
      "num_dependents                                     1000 non-null int64\n",
      "class                                              1000 non-null object\n",
      "checking_status_'0<=X<200'                         1000 non-null uint8\n",
      "checking_status_'<0'                               1000 non-null uint8\n",
      "checking_status_'>=200'                            1000 non-null uint8\n",
      "checking_status_'no checking'                      1000 non-null uint8\n",
      "credit_history_'all paid'                          1000 non-null uint8\n",
      "credit_history_'critical/other existing credit'    1000 non-null uint8\n",
      "credit_history_'delayed previously'                1000 non-null uint8\n",
      "credit_history_'existing paid'                     1000 non-null uint8\n",
      "credit_history_'no credits/all paid'               1000 non-null uint8\n",
      "purpose_'domestic appliance'                       1000 non-null uint8\n",
      "purpose_'new car'                                  1000 non-null uint8\n",
      "purpose_'used car'                                 1000 non-null uint8\n",
      "purpose_business                                   1000 non-null uint8\n",
      "purpose_education                                  1000 non-null uint8\n",
      "purpose_furniture/equipment                        1000 non-null uint8\n",
      "purpose_other                                      1000 non-null uint8\n",
      "purpose_radio/tv                                   1000 non-null uint8\n",
      "purpose_repairs                                    1000 non-null uint8\n",
      "purpose_retraining                                 1000 non-null uint8\n",
      "savings_status_'100<=X<500'                        1000 non-null uint8\n",
      "savings_status_'500<=X<1000'                       1000 non-null uint8\n",
      "savings_status_'<100'                              1000 non-null uint8\n",
      "savings_status_'>=1000'                            1000 non-null uint8\n",
      "savings_status_'no known savings'                  1000 non-null uint8\n",
      "employment_'1<=X<4'                                1000 non-null uint8\n",
      "employment_'4<=X<7'                                1000 non-null uint8\n",
      "employment_'<1'                                    1000 non-null uint8\n",
      "employment_'>=7'                                   1000 non-null uint8\n",
      "employment_unemployed                              1000 non-null uint8\n",
      "personal_status_'female div/dep/mar'               1000 non-null uint8\n",
      "personal_status_'male div/sep'                     1000 non-null uint8\n",
      "personal_status_'male mar/wid'                     1000 non-null uint8\n",
      "personal_status_'male single'                      1000 non-null uint8\n",
      "other_parties_'co applicant'                       1000 non-null uint8\n",
      "other_parties_guarantor                            1000 non-null uint8\n",
      "other_parties_none                                 1000 non-null uint8\n",
      "property_magnitude_'life insurance'                1000 non-null uint8\n",
      "property_magnitude_'no known property'             1000 non-null uint8\n",
      "property_magnitude_'real estate'                   1000 non-null uint8\n",
      "property_magnitude_car                             1000 non-null uint8\n",
      "other_payment_plans_bank                           1000 non-null uint8\n",
      "other_payment_plans_none                           1000 non-null uint8\n",
      "other_payment_plans_stores                         1000 non-null uint8\n",
      "housing_'for free'                                 1000 non-null uint8\n",
      "housing_own                                        1000 non-null uint8\n",
      "housing_rent                                       1000 non-null uint8\n",
      "job_'high qualif/self emp/mgmt'                    1000 non-null uint8\n",
      "job_'unemp/unskilled non res'                      1000 non-null uint8\n",
      "job_'unskilled resident'                           1000 non-null uint8\n",
      "job_skilled                                        1000 non-null uint8\n",
      "own_telephone_none                                 1000 non-null uint8\n",
      "own_telephone_yes                                  1000 non-null uint8\n",
      "foreign_worker_no                                  1000 non-null uint8\n",
      "foreign_worker_yes                                 1000 non-null uint8\n",
      "dtypes: int64(7), object(1), uint8(54)\n",
      "memory usage: 115.3+ KB\n"
     ]
    }
   ],
   "source": [
    "credit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have doubled the number of features ($\\sim$ 50 ). Usually it's not a good idea to increase the number of features, on the contrary it's important to reduce the number of features to use only the more 'useful'(PCA algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the target in the datset from the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit.drop(['class'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's encode the target field (good,bad = 0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bad', 'good'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "Y = credit['class'].values\n",
    "Y = le.fit_transform(Y)\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare the train,validation and test set with a well defined percentage distribution of data :(X_train =70% X, X_valid = 15% X, X_test = 15% X)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 61) (150, 61) (150, 61)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_valid,Y_train,Y_valid = train_test_split(X,Y,test_size = 0.15, random_state  = 0 )\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X_train,Y_train,test_size = 0.176, random_state  = 0 )\n",
    "\n",
    "print(X_train.shape,X_valid.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's normalize the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mm = MinMaxScaler()\n",
    "X_train = mm.fit_transform(X_train)\n",
    "X_valid = mm.transform(X_valid)\n",
    "X_test = mm.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis : Decision Tree VS Random Forest vs Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's develop the model and let's tune the deepness of the tree. It's our hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set = 0.682857, accuracy on validation set = 0.740000 with max_depth = 1\n",
      "Accuracy on train set = 0.682857, accuracy on validation set = 0.740000 with max_depth = 2\n",
      "Accuracy on train set = 0.725714, accuracy on validation set = 0.740000 with max_depth = 3\n",
      "Accuracy on train set = 0.750000, accuracy on validation set = 0.733333 with max_depth = 4\n",
      "Accuracy on train set = 0.782857, accuracy on validation set = 0.726667 with max_depth = 5\n",
      "Accuracy on train set = 0.815714, accuracy on validation set = 0.673333 with max_depth = 6\n",
      "Accuracy on train set = 0.831429, accuracy on validation set = 0.713333 with max_depth = 7\n",
      "Accuracy on train set = 0.848571, accuracy on validation set = 0.686667 with max_depth = 8\n",
      "Accuracy on train set = 0.880000, accuracy on validation set = 0.640000 with max_depth = 9\n",
      "Accuracy on train set = 0.887143, accuracy on validation set = 0.666667 with max_depth = 10\n",
      "Accuracy on train set = 0.924286, accuracy on validation set = 0.686667 with max_depth = 11\n",
      "Accuracy on train set = 0.930000, accuracy on validation set = 0.660000 with max_depth = 12\n",
      "Accuracy on train set = 0.952857, accuracy on validation set = 0.686667 with max_depth = 13\n",
      "Accuracy on train set = 0.965714, accuracy on validation set = 0.693333 with max_depth = 14\n",
      "Accuracy on train set = 0.977143, accuracy on validation set = 0.673333 with max_depth = 15\n",
      "Accuracy on train set = 0.987143, accuracy on validation set = 0.660000 with max_depth = 16\n",
      "Accuracy on train set = 0.992857, accuracy on validation set = 0.680000 with max_depth = 17\n",
      "Accuracy on train set = 0.998571, accuracy on validation set = 0.680000 with max_depth = 18\n",
      "Accuracy on train set = 1.000000, accuracy on validation set = 0.660000 with max_depth = 19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "for i in range(1,20):\n",
    "    dtc = DecisionTreeClassifier(criterion ='entropy',max_depth = i,random_state  = 42)\n",
    "    dtc.fit(X_train,Y_train)\n",
    "    \n",
    "    Y_train_predict = dtc.predict(X_train)\n",
    "    Y_valid_predict =  dtc.predict(X_valid)\n",
    "\n",
    "    class_proba = dtc.predict_proba(X_valid)\n",
    "\n",
    "    accuracy_valid= dtc.score(X_test,Y_test)\n",
    "    accuracy_train= dtc.score(X_train,Y_train)\n",
    "\n",
    "    print('Accuracy on train set = %f, accuracy on validation set = %f with max_depth = %d' %(accuracy_train,accuracy_valid,i))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can the tuning of the hyperparameters using [GridSerchCV()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class. It's in scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy', 'max_depth': 3, 'random_state': 42}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "dtcg = DecisionTreeClassifier()\n",
    "param = [{'criterion':['entropy','gini'],'max_depth':[el for el in range(1,20)],'random_state': [42]}]\n",
    "gridsearch = GridSearchCV(dtcg,param,scoring = 'accuracy',return_train_score = True,cv = 3)# with cv = None it uses 5-fold cross validation\n",
    "gridsearch.fit(X_train,Y_train)\n",
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best value for the deepness(*max_depth* parameter) of the decision tree is i = 3 when i've started the kernel. Besides we can see the presence of a strong overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.740000\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(criterion ='entropy',max_depth = 3,random_state  = 42)\n",
    "dtc.fit(X_train,Y_train)\n",
    "Y_test_predict =  dtc.predict(X_test)\n",
    "class_proba_test = dtc.predict_proba(X_test)\n",
    "accuracy_test= dtc.score(X_test,Y_test)\n",
    "print('Accuracy on test set = %f' %(accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precsion, recall ad F1 are: 0.776923, 0.909910 and 0.838174\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test,Y_test_predict)\n",
    "p = precision_score(Y_test,Y_test_predict)\n",
    "r = recall_score(Y_test,Y_test_predict)\n",
    "f1 = f1_score(Y_test,Y_test_predict)\n",
    "print('Precsion, recall ad F1 are: %f, %f and %f'%(p,r,f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set = 0.730000, accuracy on validation set = 0.700000 with n_estimators = 2\n",
      "Accuracy on train set = 0.741429, accuracy on validation set = 0.720000 with n_estimators = 3\n",
      "Accuracy on train set = 0.740000, accuracy on validation set = 0.733333 with n_estimators = 4\n",
      "Accuracy on train set = 0.738571, accuracy on validation set = 0.740000 with n_estimators = 5\n",
      "Accuracy on train set = 0.738571, accuracy on validation set = 0.726667 with n_estimators = 6\n",
      "Accuracy on train set = 0.738571, accuracy on validation set = 0.733333 with n_estimators = 7\n",
      "Accuracy on train set = 0.744286, accuracy on validation set = 0.746667 with n_estimators = 8\n",
      "Accuracy on train set = 0.744286, accuracy on validation set = 0.733333 with n_estimators = 9\n",
      "Accuracy on train set = 0.765714, accuracy on validation set = 0.726667 with n_estimators = 10\n",
      "Accuracy on train set = 0.764286, accuracy on validation set = 0.726667 with n_estimators = 11\n",
      "Accuracy on train set = 0.764286, accuracy on validation set = 0.726667 with n_estimators = 12\n",
      "Accuracy on train set = 0.751429, accuracy on validation set = 0.740000 with n_estimators = 13\n",
      "Accuracy on train set = 0.747143, accuracy on validation set = 0.746667 with n_estimators = 14\n",
      "Accuracy on train set = 0.735714, accuracy on validation set = 0.740000 with n_estimators = 15\n",
      "Accuracy on train set = 0.741429, accuracy on validation set = 0.740000 with n_estimators = 16\n",
      "Accuracy on train set = 0.731429, accuracy on validation set = 0.753333 with n_estimators = 17\n",
      "Accuracy on train set = 0.724286, accuracy on validation set = 0.733333 with n_estimators = 18\n",
      "Accuracy on train set = 0.722857, accuracy on validation set = 0.753333 with n_estimators = 19\n",
      "Accuracy on train set = 0.724286, accuracy on validation set = 0.733333 with n_estimators = 20\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 21\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.746667 with n_estimators = 22\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 23\n",
      "Accuracy on train set = 0.721429, accuracy on validation set = 0.740000 with n_estimators = 24\n",
      "Accuracy on train set = 0.721429, accuracy on validation set = 0.746667 with n_estimators = 25\n",
      "Accuracy on train set = 0.722857, accuracy on validation set = 0.746667 with n_estimators = 26\n",
      "Accuracy on train set = 0.727143, accuracy on validation set = 0.740000 with n_estimators = 27\n",
      "Accuracy on train set = 0.721429, accuracy on validation set = 0.746667 with n_estimators = 28\n",
      "Accuracy on train set = 0.727143, accuracy on validation set = 0.740000 with n_estimators = 29\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.733333 with n_estimators = 30\n",
      "Accuracy on train set = 0.721429, accuracy on validation set = 0.726667 with n_estimators = 31\n",
      "Accuracy on train set = 0.721429, accuracy on validation set = 0.726667 with n_estimators = 32\n",
      "Accuracy on train set = 0.724286, accuracy on validation set = 0.726667 with n_estimators = 33\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.726667 with n_estimators = 34\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 35\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.733333 with n_estimators = 36\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.740000 with n_estimators = 37\n",
      "Accuracy on train set = 0.722857, accuracy on validation set = 0.733333 with n_estimators = 38\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.740000 with n_estimators = 39\n",
      "Accuracy on train set = 0.724286, accuracy on validation set = 0.740000 with n_estimators = 40\n",
      "Accuracy on train set = 0.721429, accuracy on validation set = 0.740000 with n_estimators = 41\n",
      "Accuracy on train set = 0.721429, accuracy on validation set = 0.740000 with n_estimators = 42\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.740000 with n_estimators = 43\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.740000 with n_estimators = 44\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.740000 with n_estimators = 45\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 46\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 47\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 48\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 49\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 50\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 51\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 52\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 53\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.740000 with n_estimators = 54\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 55\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.740000 with n_estimators = 56\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 57\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.740000 with n_estimators = 58\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 59\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.746667 with n_estimators = 60\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 61\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 62\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.746667 with n_estimators = 63\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 64\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 65\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 66\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.733333 with n_estimators = 67\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.733333 with n_estimators = 68\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 69\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 70\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 71\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 72\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.733333 with n_estimators = 73\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.733333 with n_estimators = 74\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.733333 with n_estimators = 75\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.733333 with n_estimators = 76\n",
      "Accuracy on train set = 0.721429, accuracy on validation set = 0.733333 with n_estimators = 77\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 78\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.740000 with n_estimators = 79\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 80\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 81\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 82\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 83\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 84\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.740000 with n_estimators = 85\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 86\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.740000 with n_estimators = 87\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.740000 with n_estimators = 88\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.740000 with n_estimators = 89\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.740000 with n_estimators = 90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.740000 with n_estimators = 91\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.740000 with n_estimators = 92\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 93\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.740000 with n_estimators = 94\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 95\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 96\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 97\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 98\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 99\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 100\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 101\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 102\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 103\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 104\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 105\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 106\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 107\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 108\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 109\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 110\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 111\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 112\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 113\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 114\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 115\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 116\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.746667 with n_estimators = 117\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.746667 with n_estimators = 118\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.746667 with n_estimators = 119\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 120\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 121\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 122\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 123\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 124\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 125\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 126\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 127\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.740000 with n_estimators = 128\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 129\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 130\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 131\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 132\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 133\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.726667 with n_estimators = 134\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.726667 with n_estimators = 135\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.726667 with n_estimators = 136\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 137\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 138\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 139\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.733333 with n_estimators = 140\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.733333 with n_estimators = 141\n",
      "Accuracy on train set = 0.722857, accuracy on validation set = 0.733333 with n_estimators = 142\n",
      "Accuracy on train set = 0.721429, accuracy on validation set = 0.733333 with n_estimators = 143\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.726667 with n_estimators = 144\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 145\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 146\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 147\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 148\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 149\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 150\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 151\n",
      "Accuracy on train set = 0.720000, accuracy on validation set = 0.726667 with n_estimators = 152\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.726667 with n_estimators = 153\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 154\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 155\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.733333 with n_estimators = 156\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.726667 with n_estimators = 157\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.726667 with n_estimators = 158\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.726667 with n_estimators = 159\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.726667 with n_estimators = 160\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 161\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 162\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 163\n",
      "Accuracy on train set = 0.718571, accuracy on validation set = 0.740000 with n_estimators = 164\n",
      "Accuracy on train set = 0.717143, accuracy on validation set = 0.740000 with n_estimators = 165\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 166\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 167\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 168\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 169\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 170\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.740000 with n_estimators = 171\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.733333 with n_estimators = 172\n",
      "Accuracy on train set = 0.715714, accuracy on validation set = 0.733333 with n_estimators = 173\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.733333 with n_estimators = 174\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 175\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.733333 with n_estimators = 176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.733333 with n_estimators = 177\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.733333 with n_estimators = 178\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 179\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 180\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 181\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 182\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 183\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.733333 with n_estimators = 184\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.733333 with n_estimators = 185\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.733333 with n_estimators = 186\n",
      "Accuracy on train set = 0.714286, accuracy on validation set = 0.733333 with n_estimators = 187\n",
      "Accuracy on train set = 0.711429, accuracy on validation set = 0.733333 with n_estimators = 188\n",
      "Accuracy on train set = 0.711429, accuracy on validation set = 0.733333 with n_estimators = 189\n",
      "Accuracy on train set = 0.711429, accuracy on validation set = 0.733333 with n_estimators = 190\n",
      "Accuracy on train set = 0.711429, accuracy on validation set = 0.733333 with n_estimators = 191\n",
      "Accuracy on train set = 0.711429, accuracy on validation set = 0.733333 with n_estimators = 192\n",
      "Accuracy on train set = 0.711429, accuracy on validation set = 0.733333 with n_estimators = 193\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 194\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 195\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 196\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 197\n",
      "Accuracy on train set = 0.712857, accuracy on validation set = 0.733333 with n_estimators = 198\n",
      "Accuracy on train set = 0.710000, accuracy on validation set = 0.733333 with n_estimators = 199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "trees = []\n",
    "for j in range(2,200):\n",
    "    rfc = RandomForestClassifier(n_estimators = j ,criterion ='entropy',max_depth = 3,random_state  = 42)\n",
    "    rfc.fit(X_train,Y_train)\n",
    "    trees.append(rfc.estimators_)\n",
    "    \n",
    "    Y_train_predict = rfc.predict(X_train)\n",
    "    Y_valid_predict =  rfc.predict(X_valid)\n",
    "\n",
    "    class_proba = rfc.predict_proba(X_valid)\n",
    "\n",
    "    accuracy_valid= rfc.score(X_valid,Y_valid)\n",
    "    accuracy_train= rfc.score(X_train,Y_train)\n",
    "\n",
    "    print('Accuracy on train set = %f, accuracy on validation set = %f with n_estimators = %d' %(accuracy_train,accuracy_valid,j))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'entropy',\n",
       " 'max_depth': 3,\n",
       " 'n_estimators': 13,\n",
       " 'random_state': 42}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcg = RandomForestClassifier()\n",
    "param = [{'n_estimators' :[el for el in range(2,200)], 'criterion' :['entropy'],'max_depth' :[3],'random_state' : [42],}]\n",
    "gridsearch = GridSearchCV(rfcg,param,scoring = 'accuracy',return_train_score = True,cv = 3)\n",
    "gridsearch.fit(X_train,Y_train)\n",
    "gridsearch.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set = 0.760000\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = 74 ,criterion ='entropy',max_depth = 3,random_state  = 42)\n",
    "rfc.fit(X_train,Y_train)\n",
    "trees = rfc.estimators_\n",
    "\n",
    "Y_test_predict =  rfc.predict(X_test)\n",
    "class_proba = rfc.predict_proba(X_test)\n",
    "\n",
    "accuracy_test= rfc.score(X_test,Y_test)\n",
    "print('Accuracy on test set = %f' %(accuracy_test))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precsion, recall ad F1 are: 0.755102, 1.000000 and 0.860465\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,precision_score,recall_score\n",
    "cm = confusion_matrix(Y_test,Y_test_predict)\n",
    "p = precision_score(Y_test,Y_test_predict)\n",
    "r = recall_score(Y_test,Y_test_predict)\n",
    "f1 = f1_score(Y_test,Y_test_predict)\n",
    "print('Precsion, recall ad F1 are: %f, %f and %f'%(p,r,f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are several good values for the number of trees in the forest(*n_estimators* parameter). I've chosen  j=74 when i start the kernel,even if GridSearchCv has advised j=13 with the same result(you can try). Besides we can still see the presence of overfitting but it is lower than the single decisione tree, thanks to the ensemble method.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_tr = {}\n",
    "accuracy_v = {}\n",
    "dic_train = {}\n",
    "hyperparameters = [('l2','lbfgs'),('l2','newton-cg',),('l2','sag'),('l2','sag'),('l1','saga')]\n",
    "\n",
    "for couple in hyperparameters:\n",
    "    lr  = LogisticRegression( random_state=42,penalty = couple[0], solver = couple[1])\n",
    "    lr.fit(X_train,Y_train)\n",
    "    Y_predict_train = lr.predict(X_train)\n",
    "    Y_predict_valid = lr.predict(X_valid)\n",
    "    \n",
    "    accuracy_tr[couple] = accuracy_score(Y_train,Y_predict_train)# I save in a dictionary the hyperparameters as (tuple) keya and with accuracy as value.\n",
    "    accuracy_v[couple] = accuracy_score(Y_valid,Y_predict_valid)# See above.\n",
    "    \n",
    "for key in dic_train:\n",
    "    print(key,accuracy_tr[key],accuracy_v[key])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we chose, as hyperparameters of the logistic regression on the test set, a **L1 regularization**, *penalty = 'l1'* , and an optimization algorithm called **SAGA**,*solver = 'saga'*. This algorithm combine simulated annealing and genetic algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set 0.798571,accuracy on validation set 0.720000 and accuracy on test set 0.746667\n"
     ]
    }
   ],
   "source": [
    "lr  = LogisticRegression( random_state=42,penalty = 'l1', solver = 'saga')\n",
    "lr.fit(X_train,Y_train)\n",
    "Y_predict_test = lr.predict(X_test)\n",
    "accuracy_t = accuracy_score(Y_test,Y_predict_test)\n",
    "\n",
    "print('Accuracy on train set %f,accuracy on validation set %f and accuracy on test set %f'%(accuracy_tr[('l1','saga')],accuracy_v[('l1','saga')],accuracy_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precsion, recall ad F1 are: 0.801653, 0.873874 and 0.836207\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(Y_test,Y_test_predict)\n",
    "p = precision_score(Y_test,Y_predict_test)\n",
    "r = recall_score(Y_test,Y_predict_test)\n",
    "f1 = f1_score(Y_test,Y_predict_test)\n",
    "print('Precsion, recall ad F1 are: %f, %f and %f'%(p,r,f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the tree devolped with the DecisionTreeClassifier. We need to install [graphviz](http://www.graphviz.org/) and to execute the following script. After that, we will have the tree in a file.dot to converte. We have to open the shell in the graphviz folder,precisely **bin** folder, as administrator and excute the command :**dot -Tps filename.dot -o outfile.png**   ( .png if you want a file.png but there are others file extentions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "dotfile = open(\"dtc.dot\", 'w')\n",
    "export_graphviz(dtc, out_file = dotfile, feature_names = credit.columns.drop(\"class\"),class_names = 'class')\n",
    "dotfile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this analysis we can say:\n",
    "- Preprocessing the data it's not an option : it's the starting point and essential part of the whole work. We have to look carefully and straight in the \"eyes of the dataset\"\n",
    "- Decision Tree and Random Forest are very powerful algorithms for classification. Random Forest,in particular, is more stable than a simple Decision Tree. Even Logistic Regression is a very good algorithm for (binary) classification: in this case is better than a Decision Tree.\n",
    "- The tuning of the hyperparameters is a thorny part in the test of the model.\n",
    "<br><br>\n",
    "We can compare our results for the accuracy of the models with that presents in the pipelines ad this [link](https://www.openml.org/t/31). Not bad!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
